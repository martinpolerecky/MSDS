{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "069f66d81507ea520c1fe5098352b437",
     "grade": false,
     "grade_id": "cell-ea989c7a4eb25b70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cdeafa5886528c497f33ffde32d9b7bb",
     "grade": false,
     "grade_id": "cell-476e59a408937946",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "MV_users = pd.read_csv('data/users.csv')\n",
    "MV_movies = pd.read_csv('data/movies.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map the movie ID to the index\n",
    "users = list(MV_users['uID'])\n",
    "movies = list(MV_movies['mID'])\n",
    "\n",
    "mv_idx_dict = dict(zip(MV_movies.mID,list(range(len(MV_movies)))))\n",
    "usr_idx_dict = dict(zip(MV_users.uID,list(range(len(MV_users)))))\n",
    "\n",
    "# Create the rating matrix\n",
    "mv_idxs = [mv_idx_dict[x] for x in train.mID] \n",
    "usr_idxs = [usr_idx_dict[x] for x in train.uID]\n",
    "\n",
    "rating_train = list(train.rating)\n",
    "Mr = np.array(coo_matrix((rating_train, (usr_idxs, mv_idxs)), shape=(len(users), len(movies))).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3883)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mr.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.029853\n"
     ]
    }
   ],
   "source": [
    "sparsity = len(Mr.nonzero()[0]) / float(Mr.shape[0] * Mr.shape[1])\n",
    "print(\"Sparsity: %.6f\" % sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train NMF model\n",
    "model = NMF(n_components=20, init='random', random_state=0)\n",
    "W = model.fit_transform(Mr)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6040, 20)\n",
      "(20, 3883)\n"
     ]
    }
   ],
   "source": [
    "print(W.shape)\n",
    "print(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_movie_test = [mv_idx_dict[x] for x in test.mID] \n",
    "ind_user_test = [usr_idx_dict[x] for x in test.uID]\n",
    "rating_test = list(test.rating)\n",
    "Mr_test = np.array(coo_matrix((rating_test, (ind_user_test, ind_movie_test)), shape=(len(users), len(movies))).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3883)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mr_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.012794\n",
      "(6040, 3883)\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "sparsity_test = len(Mr_test.nonzero()[0]) / float(Mr_test.shape[0] * Mr_test.shape[1])\n",
    "print(\"Sparsity: %.6f\" % sparsity_test)\n",
    "Mr_pred = np.dot(W,H)\n",
    "print(Mr_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.861970909347181\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(Mr_test[Mr_test.nonzero()].flatten(), Mr_pred[Mr_test.nonzero()].flatten()))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the results and why they did not work well compared to simple baseline or similarity-based methods weâ€™ve done in Module 3. Can you suggest a way(s) to fix it?\n",
    "\n",
    "*   Matrix factorization is difficult on this dataset since the data is very sparse\n",
    "*   The RMSE turned out to be around 2.86, which is abysmal compared to the recommender system from Module 3 \n",
    "*   Changing n_components or using a different loss function might produce better results\n",
    "*   KL loss would be a solid choice of a loss function since the matrix contains lots of zeroes but is also sensitive to sparse matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
